(128.2-126.5)
sqrt((17.5*17.5/1623)+(20.1*20.1/1911))
sqrt((17.5*17.5/1623)+(20.1*20.1/1911)) * 1.96
library(dplyr)
filenames <- list.files(pattern=".txt", full.names=TRUE)
tables <- lapply(filenames, read.csv)
teste <- setNames(data.frame(matrix(ncol = 5, nrow = 0)), c("Workload", "Algorithm", "TAT", "WT", "RT"))
for (i in 1:(length(tables))) {
teste[i,3] <- mean(tables[[i]][,6])
teste[i,4] <- mean(tables[[i]][,7])
teste[i,5] <- mean(tables[[i]][,8])
if(grepl("fcfs",filenames[i])){
algorithm <- "FCFS"
}
else if(grepl("rr",filenames[i])){
algorithm <- "RR"
}
else if(grepl("sjf",filenames[i])){
algorithm <- "SJF"
}
else if(grepl("srtf",filenames[i])){
algorithm <- "SRTF"
}
if(grepl("w1",filenames[i])){
workload <- "1"
}
else if(grepl("w2",filenames[i])){
workload <- "2"
}
else if(grepl("w3",filenames[i])){
workload <- "3"
}
teste[i,2] <- algorithm
teste[i,1] <- workload
#================ Comp workload 1 ===========================#
aov_cw1 = aov(RT~Workload, data = teste)
summary(aov_cw1)
#Ver se os residuos seguem uma distribuição normal
png(file="~/Desktop/Rosarinho/Mestrado/MEI/assignment/meta2/sim_out/qqnorm_RT_cw1.png",
width=600, height=350)
qqnorm(aov_w3$residuals)
qqline(aov_w3$residuals)
dev.off()
#para ter a certeza que seguem uma distribuicao normal podemos fazer o shapiro test
shapiro.test(aov_cw1$res)
#Ver se as variâncias são homogeneas
bartlett.test(RT~Workload, data = teste)
#Investigar comparações multiplas
t5 = TukeyHSD(aov_cw1, alternative="two.sided")
t5
png(file="~/Desktop/Rosarinho/Mestrado/MEI/assignment/meta2/sim_out/tukey_RT_cw3.png",
width=600, height=350)
plot(t5)
dev.off()
#================ Comp workload 1 ===========================#
aov_cw1 = aov(RT~Workload, data = teste)
summary(aov_cw1)
#Ver se os residuos seguem uma distribuição normal
png(file="~/Desktop/Rosarinho/Mestrado/MEI/assignment/meta2/sim_out/qqnorm_RT_cw1.png",
width=600, height=350)
qqnorm(aov_w3$residuals)
qqline(aov_w3$residuals)
dev.off()
#para ter a certeza que seguem uma distribuicao normal podemos fazer o shapiro test
shapiro.test(aov_cw1$res)
#Ver se as variâncias são homogeneas
bartlett.test(RT~Workload, data = teste)
#Investigar comparações multiplas
t5 = TukeyHSD(aov_cw1, alternative="two.sided")
t5
png(file="~/Desktop/Rosarinho/Mestrado/MEI/assignment/meta2/sim_out/tukey_RT_cw3.png",
width=600, height=350)
plot(t5)
dev.off()
setwd("~/Desktop/Rosarinho/Mestrado/MEI/assignment/meta2/sim_out")
#================Response Time===========================#
w1_data <- teste %>% filter(Workload == "1")
w2_data <- teste %>% filter(Workload == "2")
w3_data <- teste %>% filter(Workload == "3")
#================Workload 1===========================#
aov_w1 = aov(RT~Algorithm, data = w1_data)
summary(aov_w1)
#Ver se os residuos seguem uma distribuição normal
png(file="~/Desktop/Rosarinho/Mestrado/MEI/assignment/meta2/sim_out/qqnorm_RT_w1.png",
width=600, height=350)
qqnorm(aov_w1$residuals)
qqline(aov_w1$residuals)
dev.off()
#para ter a certeza que seguem uma distribuicao normal podemos fazer o shapiro test
shapiro.test(aov_w1$res)
#Ver se as variâncias são homogeneas
bartlett.test(RT~Algorithm, data = w1_data)
#Investigar comparações multiplas
t = TukeyHSD(aov_w1, alternative="two.sided")
t
png(file="~/Desktop/Rosarinho/Mestrado/MEI/assignment/meta2/sim_out/tukey_RT_w1.png",
width=600, height=350)
plot(t)
dev.off()
#================Workload 2===========================#
aov_w2 = aov(RT~Algorithm, data = w2_data)
summary(aov_w2)
#Ver se os residuos seguem uma distribuição normal
png(file="~/Desktop/Rosarinho/Mestrado/MEI/assignment/meta2/sim_out/qqnorm_RT_w2.png",
width=600, height=350)
qqnorm(aov_w2$residuals)
qqline(aov_w2$residuals)
dev.off()
#para ter a certeza que seguem uma distribuicao normal podemos fazer o shapiro test
shapiro.test(aov_w2$res)
#Ver se as variâncias são homogeneas
bartlett.test(RT~Algorithm, data = w2_data)
#Investigar comparações multiplas
t1 = TukeyHSD(aov_w2, alternative="two.sided")
t1
png(file="~/Desktop/Rosarinho/Mestrado/MEI/assignment/meta2/sim_out/tukey_RT_w2.png",
width=600, height=350)
plot(t1)
dev.off()
#================Workload 3===========================#
aov_w3 = aov(RT~Algorithm, data = w3_data)
summary(aov_w3)
#Ver se os residuos seguem uma distribuição normal
png(file="~/Desktop/Rosarinho/Mestrado/MEI/assignment/meta2/sim_out/qqnorm_RT_w3.png",
width=600, height=350)
qqnorm(aov_w3$residuals)
qqline(aov_w3$residuals)
dev.off()
#para ter a certeza que seguem uma distribuicao normal podemos fazer o shapiro test
shapiro.test(aov_w3$res)
#Ver se as variâncias são homogeneas
bartlett.test(RT~Algorithm, data = w3_data)
#Investigar comparações multiplas
t3 = TukeyHSD(aov_w3, alternative="two.sided")
t3
png(file="~/Desktop/Rosarinho/Mestrado/MEI/assignment/meta2/sim_out/tukey_RT_w3.png",
width=600, height=350)
plot(t3)
dev.off()
aov_cw1 = aov(RT~Workload, data = teste)
setwd("~/Desktop/Rosarinho/Mestrado/MEI/assignment/meta2/sim_out")
library(dplyr)
filenames <- list.files(pattern=".txt", full.names=TRUE)
tables <- lapply(filenames, read.csv)
teste <- setNames(data.frame(matrix(ncol = 6, nrow = 0)), c("Workload", "Algorithm", "TAT", "WT", "RT", "instance"))
verifica <- 0
index <- 1
conta_fcfs_w1 <-1
conta_rr_w1 <- 1
conta_sjf_w1 <- 1
conta_srtf_w1 <- 1
conta_fcfs_w2 <-1
conta_rr_w2 <- 1
conta_sjf_w2 <- 1
conta_srtf_w2 <- 1
conta_fcfs_w3 <-1
conta_rr_w3 <- 1
conta_sjf_w3 <- 1
conta_srtf_w3 <- 1
if_fcfs <- 0
is_rr <- 0
is_sjf <- 0
is_srtf <-0
for (i in 1:(length(tables))) {
tat <- mean(tables[[i]][,6])
wt <- mean(tables[[i]][,7])
rt <- mean(tables[[i]][,8])
if(grepl("fcfs",filenames[i])){
if_fcfs <- 1
verifica <- 1
algorithm <- "FCFS"
}
else if(grepl("rr",filenames[i])){
if(grepl("_q_0.3",filenames[i])){
is_rr <- 1
verifica <- 1
algorithm <- "RR"
}
}
else if(grepl("sjf",filenames[i])){
is_sjf <- 1
verifica <- 1
algorithm <- "SJF"
}
else if(grepl("srtf",filenames[i])){
is_srtf <- 1
verifica <- 1
algorithm <- "SRTF"
}
if(grepl("w1",filenames[i])){
workload <- "1"
if(if_fcfs == 1){
inst <- conta_fcfs_w1
conta_fcfs_w1 <- conta_fcfs_w1+1
}
else if(is_rr == 1){
inst <- conta_rr_w1
conta_rr_w1 <- conta_rr_w1+1
}
else if(is_sjf == 1){
inst <- conta_sjf_w1
conta_sjf_w1 <- conta_sjf_w1+1
}
else if(is_srtf == 1){
inst <- conta_srtf_w1
conta_srtf_w1 <- conta_srtf_w1+1
}
}
else if(grepl("w2",filenames[i])){
workload <- "2"
if(if_fcfs == 1){
inst <- conta_fcfs_w2
conta_fcfs_w2 <- conta_fcfs_w2+1
}
else if(is_rr == 1){
inst <- conta_rr_w2
conta_rr_w2 <- conta_rr_w2+1
}
else if(is_sjf == 1){
inst <- conta_sjf_w2
conta_sjf_w2 <- conta_sjf_w2+1
}
else if(is_srtf == 1){
inst <- conta_srtf_w2
conta_srtf_w2 <- conta_srtf_w2+1
}
}
else if(grepl("w3",filenames[i])){
workload <- "3"
if(if_fcfs == 1){
inst <- conta_fcfs_w3
conta_fcfs_w3 <- conta_fcfs_w3+1
}
else if(is_rr == 1){
inst <- conta_rr_w3
conta_rr_w3 <- conta_rr_w3+1
}
else if(is_sjf == 1){
inst <- conta_sjf_w3
conta_sjf_w3 <- conta_sjf_w3+1
}
else if(is_srtf == 1){
inst <- conta_srtf_w3
conta_srtf_w3 <- conta_srtf_w3+1
}
}
if(verifica == 1){
teste[index,2] <- algorithm
teste[index,1] <- workload
teste[index,3] <- tat
teste[index,4] <- wt
teste[index,5] <- rt
teste[index,6] <- inst
index <- index+1
}
verifica <- 0
if_fcfs <- 0
is_rr <- 0
is_sjf <- 0
is_srtf <-0
}
w1_data <- teste %>% filter(Workload == "1")
w2_data <- teste %>% filter(Workload == "2")
w3_data <- teste %>% filter(Workload == "3")
#===========================================Turnaround Time===========================================#
#================ANOVA ALGORITMOS Workload 1===========================#
aov_w1_tat_erro = aov(RT~Algorithm+Error(instance), data = w1_data)
summary(aov_w1_tat_erro)
aov_w1_tat = aov(RT~Algorithm, data = w1_data)
summary(aov_w1_tat)
#Ver se os residuos seguem uma distribuição normal
png(file="~/Desktop/Rosarinho/Mestrado/MEI/assignment/meta2/sim_out/qqnorm_TAT_w1.png",
width=600, height=350)
qqnorm(aov_w1_tat$residuals)
qqline(aov_w1_tat$residuals)
dev.off()
#para ter a certeza que seguem uma distribuicao normal podemos fazer o shapiro test
shapiro.test(aov_w1_tat$res)
#Ver se as variâncias são homogeneas
bartlett.test(TAT~Algorithm, data = w1_data)
#Investigar comparações multiplas
t_tat = TukeyHSD(aov_w1_tat, alternative="two.sided")
t_tat
kruskal.test(TAT~Algorithm, data = w1_data)
aov_w2_erro_tat = aov(RT~Algorithm+Error(instance), data = w2_data)
summary(aov_w2_erro_tat)
aov_w3_erro_tat = aov(RT~Algorithm+Error(instance), data = w3_data)
summary(aov_w3_erro_tat)
kruskal.test(TAT~Algorithm, data = w3_data)
